{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Сидорова, оценка TreeTagger.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SerasLain/NLP-2019/blob/master/%D0%A1%D0%B8%D0%B4%D0%BE%D1%80%D0%BE%D0%B2%D0%B0%2C_%D0%BE%D1%86%D0%B5%D0%BD%D0%BA%D0%B0_TreeTagger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPOgMnI-81so",
        "colab_type": "text"
      },
      "source": [
        "Про существующие инструменты хорошо написано вот тут  - http://web-corpora.net/wsgi/mystemplus.wsgi/mystemplus/instructions/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6H5NM8O9BJf",
        "colab_type": "text"
      },
      "source": [
        "Не все из списка просто установить даже в колабе. Воспользуемся TreeTagger. Он хотя бы работает."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6g4DGAj9BMp",
        "colab_type": "text"
      },
      "source": [
        "Скачиваем нужные файлы по инструкции."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJSOrmGM80vJ",
        "colab_type": "code",
        "outputId": "527adf4f-9ba8-4363-9dbd-9da90cd4d56b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "!wget http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.2.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-06 17:34:47--  http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.2.tar.gz\n",
            "Resolving www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
            "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.2.tar.gz [following]\n",
            "--2019-06-06 17:34:52--  https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.2.tar.gz\n",
            "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1821366 (1.7M) [application/x-gzip]\n",
            "Saving to: ‘tree-tagger-linux-3.2.2.tar.gz’\n",
            "\n",
            "tree-tagger-linux-3 100%[===================>]   1.74M  11.3MB/s    in 0.2s    \n",
            "\n",
            "2019-06-06 17:34:52 (11.3 MB/s) - ‘tree-tagger-linux-3.2.2.tar.gz’ saved [1821366/1821366]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAH8K4T_5z8o",
        "colab_type": "code",
        "outputId": "49e863f4-2d48-490d-b6cc-a555a710e4fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "!wget http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-06 17:34:54--  http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n",
            "Resolving www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
            "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz [following]\n",
            "--2019-06-06 17:34:54--  https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n",
            "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 101810 (99K) [application/x-gzip]\n",
            "Saving to: ‘tagger-scripts.tar.gz’\n",
            "\n",
            "\rtagger-scripts.tar.   0%[                    ]       0  --.-KB/s               \rtagger-scripts.tar. 100%[===================>]  99.42K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-06-06 17:34:54 (1.96 MB/s) - ‘tagger-scripts.tar.gz’ saved [101810/101810]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SJ8rbYf5z-e",
        "colab_type": "code",
        "outputId": "601a7902-ef54-4777-80eb-47865c41ce26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!wget http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/install-tagger.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-06 17:34:57--  http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n",
            "Resolving www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
            "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/install-tagger.sh [following]\n",
            "--2019-06-06 17:34:57--  https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n",
            "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12409 (12K) [application/x-shellscript]\n",
            "Saving to: ‘install-tagger.sh’\n",
            "\n",
            "\rinstall-tagger.sh     0%[                    ]       0  --.-KB/s               \rinstall-tagger.sh   100%[===================>]  12.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-06 17:34:57 (229 MB/s) - ‘install-tagger.sh’ saved [12409/12409]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n__NxBzk50DC",
        "colab_type": "code",
        "outputId": "6b7d77a5-769c-41d7-c369-efd5d1354765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!wget http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/russian.par.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-06 17:34:59--  http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/russian.par.gz\n",
            "Resolving www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)... 129.187.148.72, 2001:4ca0:4f01::5\n",
            "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/russian.par.gz [following]\n",
            "--2019-06-06 17:34:59--  https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/russian.par.gz\n",
            "Connecting to www.cis.uni-muenchen.de (www.cis.uni-muenchen.de)|129.187.148.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 115748255 (110M) [application/x-gzip]\n",
            "Saving to: ‘russian.par.gz’\n",
            "\n",
            "russian.par.gz      100%[===================>] 110.39M  94.1MB/s    in 1.2s    \n",
            "\n",
            "2019-06-06 17:35:00 (94.1 MB/s) - ‘russian.par.gz’ saved [115748255/115748255]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUTvm68R9Qz8",
        "colab_type": "text"
      },
      "source": [
        "Устанавливаем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_Zl4nv050G0",
        "colab_type": "code",
        "outputId": "f22230f1-1fc4-4a54-ea01-d31bc09bae53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!sh install-tagger.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "TreeTagger version for PC-Linux installed.\n",
            "Tagging scripts installed.\n",
            "Russian parameter file installed.\n",
            "Path variables modified in tagging scripts.\n",
            "\n",
            "You might want to add /content/cmd and /content/bin to the PATH variable so that you do not need to specify the full path to run the tagging scripts.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83EIeB1j9TR4",
        "colab_type": "text"
      },
      "source": [
        "Предобученная модель для русского уже есть. Можно потестить."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opn4plRc50Ij",
        "colab_type": "code",
        "outputId": "b4a01dba-bd31-414e-dcfa-16ebc7240d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!echo 'Я хочу съесть яблоко!' | cmd/tree-tagger-russian "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\treading parameters ...\n",
            "\ttagging ...\n",
            "Я\tP-1-snn\tя\n",
            "хочу\tVmip1s-a-e\tхотеть\n",
            "съесть\tVmn----a-p\tсъесть\n",
            "яблоко\tNcnsan\tяблоко\n",
            "!\tSENT\t!\n",
            "\t finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va0btbvi9Y55",
        "colab_type": "text"
      },
      "source": [
        "Но тэги тут странноватые. Чтобы оценить это все на нашем корпусе, нужно будет обучить модель заново."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0V-1lxg50NF",
        "colab_type": "code",
        "outputId": "821d2aac-746c-41af-9292-af576df93fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget http://opencorpora.org/files/export/annot/annot.opcorpora.no_ambig_strict.xml.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-06 17:35:07--  http://opencorpora.org/files/export/annot/annot.opcorpora.no_ambig_strict.xml.zip\n",
            "Resolving opencorpora.org (opencorpora.org)... 148.251.2.141\n",
            "Connecting to opencorpora.org (opencorpora.org)|148.251.2.141|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2194522 (2.1M) [application/zip]\n",
            "Saving to: ‘annot.opcorpora.no_ambig_strict.xml.zip’\n",
            "\n",
            "\r          annot.opc   0%[                    ]       0  --.-KB/s               \rannot.opcorpora.no_ 100%[===================>]   2.09M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-06-06 17:35:07 (19.6 MB/s) - ‘annot.opcorpora.no_ambig_strict.xml.zip’ saved [2194522/2194522]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHLr7nmv-F3c",
        "colab_type": "code",
        "outputId": "c79d99f3-c56f-4d51-8723-7d49c594ff55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip annot.opcorpora.no_ambig_strict.xml.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  annot.opcorpora.no_ambig_strict.xml.zip\n",
            "  inflating: annot.opcorpora.no_ambig_strict.xml  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh8OpwE5-F6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lxml import etree\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCuVu_w9-bC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "open_corpora = etree.fromstring(open('annot.opcorpora.no_ambig_strict.xml', 'rb').read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y56kotO_nZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = len(open_corpora)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAi-Sq0A9num",
        "colab_type": "text"
      },
      "source": [
        "Формат файлов делаем по инструкции."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWp7bYeD-bEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = open('corpus_train.txt', 'w')\n",
        "\n",
        "vocab = defaultdict(set)\n",
        "tags = set()\n",
        "\n",
        "for sentence in open_corpora.xpath('//tokens'):\n",
        "    length = len(sentence.xpath('token'))\n",
        "    ended = False\n",
        "    for i,token in enumerate(sentence.xpath('token')):\n",
        "        word = token.xpath('@text')\n",
        "        gram_info = token.xpath('tfr/v/l/g/@v')\n",
        "        \n",
        "        if (i+1)==length and gram_info[0] == 'PNCT':\n",
        "            gram_info = ['SENT']\n",
        "            ended = True\n",
        "        \n",
        "            \n",
        "        corpus.write(word[0] + '\\t' + ','.join(gram_info) + '\\n')\n",
        "        lemma = token.xpath('tfr/v/l/@t')[0]\n",
        "        vocab[word[0].lower()].add((','.join(gram_info), lemma.lower()))\n",
        "        tags.add(','.join(gram_info))\n",
        "    \n",
        "    if not ended:\n",
        "        corpus.write('.\\tSENT\\n')\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYBPjBGICEqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJb8w_9XjbXj",
        "colab_type": "text"
      },
      "source": [
        "## Решение домашнего задания"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMfqb8_uCxW0",
        "colab_type": "code",
        "outputId": "00354893-19ac-4e47-92d9-97e0537cb6e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('corpus_train.txt', 'r') as f:\n",
        "  corpora = f.readlines()\n",
        " \n",
        "l = int(len(corpora)/3)\n",
        "print(l)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILglz9pLGZzh",
        "colab_type": "code",
        "outputId": "72c5f7de-1815-41f0-ff64-7002be58d0a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Разобьем корпус на три части\n",
        "counter = 0\n",
        "time = 0\n",
        "arr = []\n",
        "for line in corpora:\n",
        "  if counter != l-1:\n",
        "    arr.append(line)\n",
        "    counter += 1\n",
        "  else:\n",
        "    with open('train' + str(time) + '.txt', 'w') as f:\n",
        "      f.write('\\n'.join(arr))\n",
        "      arr = []\n",
        "      counter = 0\n",
        "      time += 1\n",
        "      print('get')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "get\n",
            "get\n",
            "get\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxEV-RExjjTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Обучим модели и получим тестовые предсказанич для оценки точности"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgKC1ltkHVDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import subprocess # чтобы в цикле перебрать все файлы\n",
        "\n",
        "files = {'train0.txt', 'train1.txt', 'train2.txt'}\n",
        "for i in files:\n",
        "  # i станет тестом\n",
        "  vocabulary = defaultdict(set)\n",
        "  tags = set()\n",
        "  with open(i, 'r') as f:\n",
        "    test = f.readlines()\n",
        "  corpus_test = [token.lower().split('\\t')[0] for token in test if token.split('\\t')[0] != '']\n",
        "  train = ''\n",
        "  # а остальные пойдут в трейн\n",
        "  for f in files:\n",
        "    if f != i:\n",
        "      with open(f, 'r') as file:\n",
        "        text = file.read().split('\\n\\n')\n",
        "      for line in text:\n",
        "        word_gram = line.split('\\t')\n",
        "        word = word_gram[0].lower()\n",
        "        grammar = word_gram[1]\n",
        "        tags.update(set(grammar))\n",
        "        try:\n",
        "          gram = vocab[word] # не набираю словарь заново, чтобы не мучиться с оформлением\n",
        "          vocabulary[word].update(gram)\n",
        "        except KeyError: # на самом деле, это уже не нужно\n",
        "          pass\n",
        "      train += '\\n'.join(text)\n",
        "    else:\n",
        "      pass\n",
        "  with open('test.txt', 'w') as file:\n",
        "    file.write('\\n'.join(corpus_test))\n",
        "  with open('train.txt', 'w') as file:\n",
        "    file.write(train)\n",
        "  make_vocab(vocabulary)\n",
        "  open_class(tags)\n",
        "  subprocess.call(['./bin/train-tree-tagger', 'lexicon.txt', 'open_class.txt', 'train.txt', 'model_'+i[:-3]])\n",
        "  subprocess.check_call(['./bin/tree-tagger', '-token', 'model_'+i[:-3], 'test.txt', 'output'+i])\n",
        "  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow7I0AkC9rsa",
        "colab_type": "text"
      },
      "source": [
        "Словарь создаем по инструкции."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ffrmMswF7h-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_vocab(vocab):\n",
        "  f = open('lexicon.txt', 'w')\n",
        "  for word in vocab:\n",
        "      f.write(word + '\\t')\n",
        "      f.write('\\t'.join([' '.join(pair) for pair in vocab[word]]))\n",
        "      f.write('\\n')\n",
        "  # f.write('SENT\\tSENT .')\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoUI-i1A9yS1",
        "colab_type": "text"
      },
      "source": [
        "Словарь для UNK создаем по инструкции."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1MbTCEKG4gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def open_class(tags):\n",
        "  f = open('open_class.txt', 'w')\n",
        "  \n",
        "  f.write('\\n'.join([tag for tag in tags if 'NOUN' in tag or 'VERB' in tag or 'ADJF' in tag]))\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERdxOWqdxVc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d8901ed3-dbc5-4d88-e69b-e300005a4484"
      },
      "source": [
        "# Затестим, чего мы тут понаобучали\n",
        "with open('test.txt', 'w') as f:\n",
        "  f.write('\\n'.join('мне лень учиться'.split(' ')))\n",
        "\n",
        "!./bin/tree-tagger -token model_train2. test.txt output_.txt\n",
        "\n",
        "!head output_.txt"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\treading parameters ...\n",
            "\ttagging ...\n",
            "\t finished.\n",
            "мне\tNPRO,1per,sing,datv\n",
            "лень\tADJF,Apro,Anph,plur,ablt\n",
            "учиться\tINFN,impf,intr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GrWzm7I0xBg",
        "colab_type": "text"
      },
      "source": [
        "Ну, странно, что лень не парсит, но давайте на скоры посмотрим."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgIjQbkM0WBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "9cdedcb4-2e36-441c-c902-e2e3021b71d2"
      },
      "source": [
        "!head train0.txt"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "«\tPNCT\n",
            "\n",
            "Школа\tNOUN,inan,femn,sing,nomn\n",
            "\n",
            "злословия\tNOUN,inan,neut,sing,gent\n",
            "\n",
            "»\tPNCT\n",
            "\n",
            "учит\tVERB,impf,tran,sing,3per,pres,indc\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqQK1I2jhk2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "scores = []\n",
        "test = 'train0.txt'\n",
        "\n",
        "def evalue(test):\n",
        "  # функция для сравнения\n",
        "  with open(test, 'r') as f:\n",
        "    ideal = f.read().split('\\n\\n')\n",
        "  ideal_arr = [i.split('\\t') for i in ideal]\n",
        "  with open('output'+test, 'r') as f:\n",
        "    predicted = f.read().split('\\n')\n",
        "  pred_arr = [i.split('\\t') for i in predicted]\n",
        "  preds = []\n",
        "  mistakes = Counter()\n",
        "  for i in range(len(ideal_arr)):\n",
        "    word = ideal_arr[i][0]\n",
        "    tag = set(ideal_arr[i][1].split(','))\n",
        "    pred = set(pred_arr[i][1].split(','))\n",
        "    p = len(pred&tag)/len(pred|tag)\n",
        "    preds.append(p)\n",
        "    if p < 0.5:\n",
        "      mistakes.update([(word, tuple(tag), tuple(pred))])\n",
        "  return preds, mistakes\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VirixNdV4Ff9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "bbebf4c5-70e1-418f-984b-c1fe895119c9"
      },
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "scores = []\n",
        "mistake = Counter()\n",
        "for name in files:\n",
        "  pred, mist = evalue(name)\n",
        "  scores.append(pred)\n",
        "  mistake.update(mist)\n",
        "  print('\\t'.join([name, str(np.mean(pred))]))\n",
        "  print(mistake.most_common(10))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train0.txt\t0.7284751671136274\n",
            "[(('.', ('PNCT',), ('SENT',)), 98), ((':', ('PNCT',), ('SENT',)), 48), (('»', ('SENT',), ('PNCT',)), 45), (('.', ('SENT',), ('PNCT',)), 26), ((',', ('PNCT',), ('SENT',)), 21), (('!', ('PNCT',), ('SENT',)), 17), ((')', ('SENT',), ('PNCT',)), 17), (('»', ('PNCT',), ('SENT',)), 16), ((',', ('SENT',), ('PNCT',)), 12), (('этом', ('masc', 'Anph', 'Subx', 'Apro', 'sing', 'loct', 'ADJF'), ('sing', 'loct', 'NPRO', 'neut')), 10)]\n",
            "train1.txt\t0.7415948765024158\n",
            "[(('.', ('PNCT',), ('SENT',)), 180), ((':', ('PNCT',), ('SENT',)), 76), (('»', ('SENT',), ('PNCT',)), 76), ((',', ('SENT',), ('PNCT',)), 62), ((',', ('PNCT',), ('SENT',)), 54), ((')', ('SENT',), ('PNCT',)), 43), (('!', ('PNCT',), ('SENT',)), 38), (('.', ('SENT',), ('PNCT',)), 34), (('»', ('PNCT',), ('SENT',)), 28), (('этом', ('masc', 'Anph', 'Subx', 'Apro', 'sing', 'loct', 'ADJF'), ('sing', 'loct', 'NPRO', 'neut')), 22)]\n",
            "train2.txt\t0.7141547083921705\n",
            "[(('.', ('PNCT',), ('SENT',)), 351), ((',', ('SENT',), ('PNCT',)), 163), ((':', ('PNCT',), ('SENT',)), 119), (('»', ('SENT',), ('PNCT',)), 110), ((')', ('SENT',), ('PNCT',)), 80), (('!', ('PNCT',), ('SENT',)), 65), ((',', ('PNCT',), ('SENT',)), 63), (('.', ('SENT',), ('PNCT',)), 58), (('…', ('PNCT',), ('SENT',)), 40), (('»', ('PNCT',), ('SENT',)), 33)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu__lVk17w1Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b638ec3-35a0-420a-8f7c-c401c9ac4dfd"
      },
      "source": [
        "mean_metric = np.mean(scores)\n",
        "st_d = np.std(scores)\n",
        "\n",
        "print(mean_metric, st_d, sep='\\t')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7280749173360711\t0.41315366453509567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge7PBbgt8TkU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "14e0caf3-03dd-4f11-92df-fda0db6a2bb2"
      },
      "source": [
        "# Теперь сделаем то же для pymorphy\n",
        "pip install pymorphy2\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4 (from pymorphy2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 16.7MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7 (from pymorphy2)\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y66EM0xu8kul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d8e04d6c-9f18-4d04-d72a-c4c8be5c1863"
      },
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "morph = MorphAnalyzer()\n",
        "with open(test, 'r') as f:\n",
        "  ideal = f.read().split('\\n\\n')\n",
        "ideal_arr = [i.split('\\t') for i in ideal]\n",
        "preds = []\n",
        "mistakes = Counter()\n",
        "for i in range(len(ideal_arr)):\n",
        "  word = ideal_arr[i][0]\n",
        "  tag = set(ideal_arr[i][1].split(','))\n",
        "  pred = set(str(morph.parse(word)[0].tag).replace(' ', ',').split(','))\n",
        "  p = len(pred&tag)/len(pred|tag)\n",
        "  preds.append(p)\n",
        "  if p < 0.5:\n",
        "    mistakes.update([(word, tuple(tag), tuple(pred))])\n",
        "    \n",
        "print(np.mean(preds), np.std(preds), mistakes.most_common(10))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8068258273883483 0.35672213187400725 [(('.', ('SENT',), ('PNCT',)), 2550), ((':', ('SENT',), ('PNCT',)), 130), (('?', ('SENT',), ('PNCT',)), 127), (('!', ('SENT',), ('PNCT',)), 73), (('»', ('SENT',), ('PNCT',)), 48), (('также', ('PRCL',), ('CONJ',)), 28), (('…', ('SENT',), ('PNCT',)), 26), ((')', ('SENT',), ('PNCT',)), 21), (('...', ('SENT',), ('PNCT',)), 18), ((',', ('SENT',), ('PNCT',)), 17)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPfQYh0Z6_f-",
        "colab_type": "text"
      },
      "source": [
        "Предсказания TreeTagger хуже, чем у pymorphy. И среднее отконение больше.\n",
        "Если посмотреть на частотные ошибки, то видно, что есть какой-то большой косяк с SENT/PUNCT, потому что они в общем-то роли не играют никакой. По-хорошему, надо их либо игнорировать, либо выикдывать из разбора сразу."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv4PrD3dAdaG",
        "colab_type": "text"
      },
      "source": [
        "(все, ниже никакой домашки)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGgP_oME7ZpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1c579226-07eb-4e0a-90fc-a6dffeb6e404"
      },
      "source": [
        "print(mistake.most_common(25))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(('.', ('PNCT',), ('SENT',)), 351), ((',', ('SENT',), ('PNCT',)), 163), ((':', ('PNCT',), ('SENT',)), 119), (('»', ('SENT',), ('PNCT',)), 110), ((')', ('SENT',), ('PNCT',)), 80), (('!', ('PNCT',), ('SENT',)), 65), ((',', ('PNCT',), ('SENT',)), 63), (('.', ('SENT',), ('PNCT',)), 58), (('…', ('PNCT',), ('SENT',)), 40), (('»', ('PNCT',), ('SENT',)), 33), (('?', ('PNCT',), ('SENT',)), 33), (('этом', ('masc', 'Anph', 'Subx', 'Apro', 'sing', 'loct', 'ADJF'), ('sing', 'loct', 'NPRO', 'neut')), 27), ((';', ('PNCT',), ('SENT',)), 25), (('первоисточника', ('inan', 'gent', 'masc', 'NOUN', 'sing'), ('Anph', 'Apro', 'sing', 'neut', 'loct', 'ADJF')), 24), (('Иваныч', ('anim', 'masc', 'Patr', 'NOUN', 'sing', 'Infr', 'nomn'), ('Anph', 'Apro', 'ADJF', 'plur', 'ablt')), 23), (('\"', ('SENT',), ('PNCT',)), 22), (('Примечания', ('inan', 'NOUN', 'neut', 'nomn', 'plur'), ('Apro', 'sing', 'neut', 'ADJF', 'ablt', 'Anum')), 21), (('*', ('SENT',), ('PNCT',)), 20), (('!..', ('SENT',), ('Anph', 'Apro', 'ADJF', 'plur', 'ablt')), 18), (('...', ('PNCT',), ('SENT',)), 17), ((':', ('SENT',), ('PNCT',)), 16), ((')', ('PNCT',), ('SENT',)), 15), (('Федя', ('anim', 'masc', 'NOUN', 'sing', 'Name', 'nomn'), ('Anph', 'Apro', 'ADJF', 'plur', 'ablt')), 15), (('?..', ('SENT',), ('Anph', 'Apro', 'ADJF', 'plur', 'ablt')), 15), (('Архивировано', ('PRTS', 'pssv', 'neut', 'sing', 'impf', 'past'), ('Apro', 'sing', 'neut', 'ADJF', 'ablt', 'Anum')), 15)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DagCFAjER3yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4OyesBr97wT",
        "colab_type": "text"
      },
      "source": [
        "Ещё можно просто обучить нейронку на этих же данных. Построим модель, которая предсказывает часть речи и одушевленность. Остальные тэги можно добавить по аналогии."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6gGX5EXhk54",
        "colab_type": "code",
        "outputId": "e382d287-d42b-46df-e917-260b423cb40a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXsYDfvrFEaz",
        "colab_type": "text"
      },
      "source": [
        "Соберем корпус в список."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5iNhTg-hk87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "vocab = defaultdict(set)\n",
        "tags = set()\n",
        "\n",
        "for sentence in open_corpora.xpath('//tokens'):\n",
        "    sent = []\n",
        "    for token in sentence.xpath('token'):\n",
        "        word = token.xpath('@text')\n",
        "        gram_info = token.xpath('tfr/v/l/g/@v')\n",
        "        \n",
        "        \n",
        "            \n",
        "        sent.append(word + gram_info)\n",
        "    corpus.append(sent)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRhYKi5JFNv9",
        "colab_type": "text"
      },
      "source": [
        "Создадим словарь для слов и частей речи. По одушевленности и другим тэгам проще построить словарь вручную."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SloEf3JMHMq7",
        "colab_type": "code",
        "outputId": "9ca23a3d-cda8-4ba8-825f-3811c4811507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "corpus[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['«', 'PNCT'],\n",
              " ['Школа', 'NOUN', 'inan', 'femn', 'sing', 'nomn'],\n",
              " ['злословия', 'NOUN', 'inan', 'neut', 'sing', 'gent'],\n",
              " ['»', 'PNCT'],\n",
              " ['учит', 'VERB', 'impf', 'tran', 'sing', '3per', 'pres', 'indc'],\n",
              " ['прикусить', 'INFN', 'perf', 'tran'],\n",
              " ['язык', 'NOUN', 'inan', 'masc', 'sing', 'accs']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMa9OGsVlQ3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Counter()\n",
        "poses = Counter()\n",
        "\n",
        "\n",
        "for sent in corpus:\n",
        "  for word, pos, *tags in sent:\n",
        "    vocab[word.lower()] += 1\n",
        "    poses[pos] += 1\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQNISgpXFQW_",
        "colab_type": "text"
      },
      "source": [
        "Возьмем только слова, встретившиеся 3+ раз."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqpx4Df3wddO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = {word for word,c in vocab.most_common() if c > 3}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAV7d5u0l914",
        "colab_type": "code",
        "outputId": "28b68f12-f003-49ac-8b41-718c557c0071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWsJKnP1l946",
        "colab_type": "code",
        "outputId": "48b28420-41ee-4394-8485-c1bc05bd3ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(poses)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKBqaMfVFU6g",
        "colab_type": "text"
      },
      "source": [
        "Сдалем словари - слово в индекс, тэг в индекс и наоборот."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oThfWNQGOXh",
        "colab_type": "text"
      },
      "source": [
        "UNK нужен для словарных слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY9qXo91lQ5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word = {i+2:word for i, word in enumerate(vocab)}\n",
        "id2word[0] = '<PAD>'\n",
        "id2word[1] = '<UNK>'\n",
        "word2id = {word:i for i, word in id2word.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgQiZm4ClQ9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2pos = {i+1:pos for i, pos in enumerate(poses)}\n",
        "id2pos[0] = '<PAD>'\n",
        "pos2id = {pos:i for i, pos in id2pos.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPPJySJFH84A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2anim = {1:'NONE', 2:'anim', 3:'inan'}\n",
        "id2anim[0] = '<PAD>'\n",
        "anim2id = {tag:i for i, tag in id2anim.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQV1HXWzme7-",
        "colab_type": "text"
      },
      "source": [
        "Создадим три списка - предложения, части речи и одушевленности. Вместо слов и тэгов в этих списках - индексы из построенных словарей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gxt7oCPmdUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents_ids = []\n",
        "poses_ids = []\n",
        "anim_ids = []\n",
        "\n",
        "for sent in corpus:\n",
        "    sents_ids.append([word2id.get(word.lower(), 1) for word, *_ in sent])\n",
        "    poses_ids.append([tag2id[tag] for word, tag, *_ in sent])\n",
        "    anim_ids_sent = []\n",
        "    \n",
        "    for word, pos, *tags in sent:\n",
        "      anim_tag = 1\n",
        "      for tag in tags:\n",
        "        if tag in anim2id:\n",
        "          anim_tag = anim2id[tag]\n",
        "      anim_ids_sent.append(anim_tag)\n",
        "    anim_ids.append(anim_ids_sent)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH08lR5ipBBN",
        "colab_type": "code",
        "outputId": "30906557-d24d-4228-febc-d1b6fb72ac22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "np.mean([len(sent) for sent in sents_ids])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.534678794769755"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbWAdBkZmOWc",
        "colab_type": "text"
      },
      "source": [
        "Приведем все предложения к одной длине. 10 больше средней длины, но и не очень большая, чтобы сильно усложнить модель."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUvScVMzqIc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9VeIBkBMNve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        " \n",
        "sents_ids_padded = pad_sequences(sents_ids, maxlen=MAX_LENGTH, padding='post',  truncating='post')\n",
        "poses_ids_padded = pad_sequences(poses_ids, maxlen=MAX_LENGTH, padding='post',  truncating='post')\n",
        "anim_ids_padded = pad_sequences(anim_ids, maxlen=MAX_LENGTH, padding='post',  truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGtReOwHGa1n",
        "colab_type": "text"
      },
      "source": [
        "Разбиваем выборку на трейн и тест."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aiF0PWTL_LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_index, test_index = train_test_split(list(range(sents_ids_padded.shape[0])),test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u1BMK5rNWAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sents, test_sents = sents_ids_padded[train_index], sents_ids_padded[test_index]\n",
        "train_pos, test_pos = poses_ids_padded[train_index], poses_ids_padded[test_index]\n",
        "train_anim, test_anim = anim_ids_padded[train_index], anim_ids_padded[test_index]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQU4RooaGy35",
        "colab_type": "text"
      },
      "source": [
        "Создаем модель (у модели два выхода - 1. для части речи 2. для одушевленности)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHaLrN_onVwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, LSTM, Input, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from keras.optimizers import Adam\n",
        " \n",
        "\n",
        "inp = Input(shape=(MAX_LENGTH, ))\n",
        "# создаем эбмеддинги размерностью 8\n",
        "x = Embedding(len(word2id), 8)(inp)\n",
        "\n",
        "# пропускаем эмбединги через LSTM, чтобы модель учитывала контекст\n",
        "x = LSTM(20, return_sequences=True)(x)\n",
        "\n",
        "# каждый выход - последовательность классов\n",
        "pos = TimeDistributed(Dense(len(pos2id), activation='softmax'))(x)\n",
        "anim = TimeDistributed(Dense(len(anim2id), activation='softmax'))(x)\n",
        "\n",
        " \n",
        "model= Model(inputs=inp, outputs=[pos, anim], \n",
        "           )\n",
        " \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXgTymivtVqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd-71dFEG6uD",
        "colab_type": "text"
      },
      "source": [
        "Обучаем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM2pnjrbtMJc",
        "colab_type": "code",
        "outputId": "7054aed2-9a0e-46b1-eefa-d9c9990478e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1142
        }
      },
      "source": [
        "model.fit(x=train_sents, \n",
        "        y=[to_categorical(train_pos), to_categorical(train_anim)], \n",
        "          batch_size=128, epochs=30, validation_split=0.2)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 6754 samples, validate on 1689 samples\n",
            "Epoch 1/30\n",
            "6754/6754 [==============================] - 7s 1ms/step - loss: 4.2063 - time_distributed_3_loss: 2.9366 - time_distributed_4_loss: 1.2697 - time_distributed_3_acc: 0.4166 - time_distributed_4_acc: 0.7320 - val_loss: 3.4317 - val_time_distributed_3_loss: 2.3983 - val_time_distributed_4_loss: 1.0334 - val_time_distributed_3_acc: 0.4409 - val_time_distributed_4_acc: 0.6710\n",
            "Epoch 2/30\n",
            "6754/6754 [==============================] - 3s 453us/step - loss: 2.7577 - time_distributed_3_loss: 1.8563 - time_distributed_4_loss: 0.9014 - time_distributed_3_acc: 0.4423 - time_distributed_4_acc: 0.6681 - val_loss: 2.4113 - val_time_distributed_3_loss: 1.6215 - val_time_distributed_4_loss: 0.7898 - val_time_distributed_3_acc: 0.4811 - val_time_distributed_4_acc: 0.7019\n",
            "Epoch 3/30\n",
            "6754/6754 [==============================] - 3s 452us/step - loss: 2.1607 - time_distributed_3_loss: 1.5029 - time_distributed_4_loss: 0.6577 - time_distributed_3_acc: 0.5276 - time_distributed_4_acc: 0.7605 - val_loss: 1.9228 - val_time_distributed_3_loss: 1.3603 - val_time_distributed_4_loss: 0.5625 - val_time_distributed_3_acc: 0.5764 - val_time_distributed_4_acc: 0.7953\n",
            "Epoch 4/30\n",
            "6754/6754 [==============================] - 3s 459us/step - loss: 1.8360 - time_distributed_3_loss: 1.3114 - time_distributed_4_loss: 0.5246 - time_distributed_3_acc: 0.5965 - time_distributed_4_acc: 0.8141 - val_loss: 1.7361 - val_time_distributed_3_loss: 1.2424 - val_time_distributed_4_loss: 0.4937 - val_time_distributed_3_acc: 0.6250 - val_time_distributed_4_acc: 0.8213\n",
            "Epoch 5/30\n",
            "6754/6754 [==============================] - 3s 455us/step - loss: 1.7081 - time_distributed_3_loss: 1.2292 - time_distributed_4_loss: 0.4789 - time_distributed_3_acc: 0.6344 - time_distributed_4_acc: 0.8257 - val_loss: 1.6504 - val_time_distributed_3_loss: 1.1859 - val_time_distributed_4_loss: 0.4645 - val_time_distributed_3_acc: 0.6533 - val_time_distributed_4_acc: 0.8229\n",
            "Epoch 6/30\n",
            "6754/6754 [==============================] - 3s 456us/step - loss: 1.6366 - time_distributed_3_loss: 1.1805 - time_distributed_4_loss: 0.4560 - time_distributed_3_acc: 0.6551 - time_distributed_4_acc: 0.8265 - val_loss: 1.5909 - val_time_distributed_3_loss: 1.1446 - val_time_distributed_4_loss: 0.4463 - val_time_distributed_3_acc: 0.6604 - val_time_distributed_4_acc: 0.8233\n",
            "Epoch 7/30\n",
            "6754/6754 [==============================] - 3s 456us/step - loss: 1.5779 - time_distributed_3_loss: 1.1398 - time_distributed_4_loss: 0.4381 - time_distributed_3_acc: 0.6619 - time_distributed_4_acc: 0.8266 - val_loss: 1.5367 - val_time_distributed_3_loss: 1.1075 - val_time_distributed_4_loss: 0.4292 - val_time_distributed_3_acc: 0.6689 - val_time_distributed_4_acc: 0.8251\n",
            "Epoch 8/30\n",
            "6754/6754 [==============================] - 3s 456us/step - loss: 1.5111 - time_distributed_3_loss: 1.0932 - time_distributed_4_loss: 0.4179 - time_distributed_3_acc: 0.6791 - time_distributed_4_acc: 0.8268 - val_loss: 1.4563 - val_time_distributed_3_loss: 1.0512 - val_time_distributed_4_loss: 0.4051 - val_time_distributed_3_acc: 0.7088 - val_time_distributed_4_acc: 0.8238\n",
            "Epoch 9/30\n",
            "6754/6754 [==============================] - 3s 455us/step - loss: 1.4167 - time_distributed_3_loss: 1.0269 - time_distributed_4_loss: 0.3898 - time_distributed_3_acc: 0.7202 - time_distributed_4_acc: 0.8306 - val_loss: 1.3476 - val_time_distributed_3_loss: 0.9758 - val_time_distributed_4_loss: 0.3719 - val_time_distributed_3_acc: 0.7311 - val_time_distributed_4_acc: 0.8332\n",
            "Epoch 10/30\n",
            "6754/6754 [==============================] - 3s 449us/step - loss: 1.2981 - time_distributed_3_loss: 0.9432 - time_distributed_4_loss: 0.3549 - time_distributed_3_acc: 0.7335 - time_distributed_4_acc: 0.8407 - val_loss: 1.2318 - val_time_distributed_3_loss: 0.8939 - val_time_distributed_4_loss: 0.3379 - val_time_distributed_3_acc: 0.7401 - val_time_distributed_4_acc: 0.8480\n",
            "Epoch 11/30\n",
            "6754/6754 [==============================] - 3s 456us/step - loss: 1.1840 - time_distributed_3_loss: 0.8625 - time_distributed_4_loss: 0.3216 - time_distributed_3_acc: 0.7590 - time_distributed_4_acc: 0.8553 - val_loss: 1.1278 - val_time_distributed_3_loss: 0.8197 - val_time_distributed_4_loss: 0.3081 - val_time_distributed_3_acc: 0.7782 - val_time_distributed_4_acc: 0.8612\n",
            "Epoch 12/30\n",
            "6754/6754 [==============================] - 3s 449us/step - loss: 1.0845 - time_distributed_3_loss: 0.7912 - time_distributed_4_loss: 0.2933 - time_distributed_3_acc: 0.7857 - time_distributed_4_acc: 0.8701 - val_loss: 1.0356 - val_time_distributed_3_loss: 0.7540 - val_time_distributed_4_loss: 0.2817 - val_time_distributed_3_acc: 0.7967 - val_time_distributed_4_acc: 0.8796\n",
            "Epoch 13/30\n",
            "6754/6754 [==============================] - 3s 451us/step - loss: 0.9981 - time_distributed_3_loss: 0.7286 - time_distributed_4_loss: 0.2694 - time_distributed_3_acc: 0.7966 - time_distributed_4_acc: 0.8867 - val_loss: 0.9579 - val_time_distributed_3_loss: 0.6973 - val_time_distributed_4_loss: 0.2607 - val_time_distributed_3_acc: 0.8044 - val_time_distributed_4_acc: 0.8931\n",
            "Epoch 14/30\n",
            "6754/6754 [==============================] - 3s 457us/step - loss: 0.9261 - time_distributed_3_loss: 0.6749 - time_distributed_4_loss: 0.2512 - time_distributed_3_acc: 0.8063 - time_distributed_4_acc: 0.8960 - val_loss: 0.8922 - val_time_distributed_3_loss: 0.6474 - val_time_distributed_4_loss: 0.2449 - val_time_distributed_3_acc: 0.8146 - val_time_distributed_4_acc: 0.8993\n",
            "Epoch 15/30\n",
            "6754/6754 [==============================] - 3s 454us/step - loss: 0.8650 - time_distributed_3_loss: 0.6274 - time_distributed_4_loss: 0.2376 - time_distributed_3_acc: 0.8199 - time_distributed_4_acc: 0.9016 - val_loss: 0.8373 - val_time_distributed_3_loss: 0.6036 - val_time_distributed_4_loss: 0.2336 - val_time_distributed_3_acc: 0.8278 - val_time_distributed_4_acc: 0.9026\n",
            "Epoch 16/30\n",
            "6754/6754 [==============================] - 3s 450us/step - loss: 0.8135 - time_distributed_3_loss: 0.5856 - time_distributed_4_loss: 0.2279 - time_distributed_3_acc: 0.8343 - time_distributed_4_acc: 0.9040 - val_loss: 0.7917 - val_time_distributed_3_loss: 0.5659 - val_time_distributed_4_loss: 0.2258 - val_time_distributed_3_acc: 0.8432 - val_time_distributed_4_acc: 0.9030\n",
            "Epoch 17/30\n",
            "6754/6754 [==============================] - 3s 451us/step - loss: 0.7704 - time_distributed_3_loss: 0.5498 - time_distributed_4_loss: 0.2206 - time_distributed_3_acc: 0.8483 - time_distributed_4_acc: 0.9056 - val_loss: 0.7550 - val_time_distributed_3_loss: 0.5347 - val_time_distributed_4_loss: 0.2202 - val_time_distributed_3_acc: 0.8539 - val_time_distributed_4_acc: 0.9036\n",
            "Epoch 18/30\n",
            "6754/6754 [==============================] - 3s 441us/step - loss: 0.7354 - time_distributed_3_loss: 0.5199 - time_distributed_4_loss: 0.2155 - time_distributed_3_acc: 0.8581 - time_distributed_4_acc: 0.9065 - val_loss: 0.7240 - val_time_distributed_3_loss: 0.5084 - val_time_distributed_4_loss: 0.2156 - val_time_distributed_3_acc: 0.8622 - val_time_distributed_4_acc: 0.9065\n",
            "Epoch 19/30\n",
            "6754/6754 [==============================] - 3s 446us/step - loss: 0.7053 - time_distributed_3_loss: 0.4945 - time_distributed_4_loss: 0.2108 - time_distributed_3_acc: 0.8660 - time_distributed_4_acc: 0.9074 - val_loss: 0.6980 - val_time_distributed_3_loss: 0.4862 - val_time_distributed_4_loss: 0.2117 - val_time_distributed_3_acc: 0.8687 - val_time_distributed_4_acc: 0.9056\n",
            "Epoch 20/30\n",
            "6754/6754 [==============================] - 3s 447us/step - loss: 0.6790 - time_distributed_3_loss: 0.4727 - time_distributed_4_loss: 0.2064 - time_distributed_3_acc: 0.8714 - time_distributed_4_acc: 0.9086 - val_loss: 0.6758 - val_time_distributed_3_loss: 0.4676 - val_time_distributed_4_loss: 0.2082 - val_time_distributed_3_acc: 0.8747 - val_time_distributed_4_acc: 0.9090\n",
            "Epoch 21/30\n",
            "6754/6754 [==============================] - 3s 450us/step - loss: 0.6559 - time_distributed_3_loss: 0.4534 - time_distributed_4_loss: 0.2025 - time_distributed_3_acc: 0.8773 - time_distributed_4_acc: 0.9100 - val_loss: 0.6551 - val_time_distributed_3_loss: 0.4508 - val_time_distributed_4_loss: 0.2043 - val_time_distributed_3_acc: 0.8772 - val_time_distributed_4_acc: 0.9085\n",
            "Epoch 22/30\n",
            "6754/6754 [==============================] - 3s 453us/step - loss: 0.6348 - time_distributed_3_loss: 0.4363 - time_distributed_4_loss: 0.1985 - time_distributed_3_acc: 0.8812 - time_distributed_4_acc: 0.9127 - val_loss: 0.6372 - val_time_distributed_3_loss: 0.4360 - val_time_distributed_4_loss: 0.2011 - val_time_distributed_3_acc: 0.8801 - val_time_distributed_4_acc: 0.9119\n",
            "Epoch 23/30\n",
            "6754/6754 [==============================] - 3s 450us/step - loss: 0.6160 - time_distributed_3_loss: 0.4211 - time_distributed_4_loss: 0.1949 - time_distributed_3_acc: 0.8846 - time_distributed_4_acc: 0.9151 - val_loss: 0.6216 - val_time_distributed_3_loss: 0.4229 - val_time_distributed_4_loss: 0.1987 - val_time_distributed_3_acc: 0.8826 - val_time_distributed_4_acc: 0.9121\n",
            "Epoch 24/30\n",
            "6754/6754 [==============================] - 3s 450us/step - loss: 0.5990 - time_distributed_3_loss: 0.4074 - time_distributed_4_loss: 0.1916 - time_distributed_3_acc: 0.8875 - time_distributed_4_acc: 0.9170 - val_loss: 0.6060 - val_time_distributed_3_loss: 0.4106 - val_time_distributed_4_loss: 0.1954 - val_time_distributed_3_acc: 0.8862 - val_time_distributed_4_acc: 0.9154\n",
            "Epoch 25/30\n",
            "6754/6754 [==============================] - 3s 451us/step - loss: 0.5830 - time_distributed_3_loss: 0.3947 - time_distributed_4_loss: 0.1882 - time_distributed_3_acc: 0.8903 - time_distributed_4_acc: 0.9197 - val_loss: 0.5930 - val_time_distributed_3_loss: 0.4001 - val_time_distributed_4_loss: 0.1929 - val_time_distributed_3_acc: 0.8874 - val_time_distributed_4_acc: 0.9160\n",
            "Epoch 26/30\n",
            "6754/6754 [==============================] - 3s 450us/step - loss: 0.5690 - time_distributed_3_loss: 0.3834 - time_distributed_4_loss: 0.1856 - time_distributed_3_acc: 0.8928 - time_distributed_4_acc: 0.9218 - val_loss: 0.5809 - val_time_distributed_3_loss: 0.3902 - val_time_distributed_4_loss: 0.1907 - val_time_distributed_3_acc: 0.8892 - val_time_distributed_4_acc: 0.9181\n",
            "Epoch 27/30\n",
            "6754/6754 [==============================] - 3s 452us/step - loss: 0.5558 - time_distributed_3_loss: 0.3732 - time_distributed_4_loss: 0.1826 - time_distributed_3_acc: 0.8944 - time_distributed_4_acc: 0.9235 - val_loss: 0.5692 - val_time_distributed_3_loss: 0.3807 - val_time_distributed_4_loss: 0.1885 - val_time_distributed_3_acc: 0.8923 - val_time_distributed_4_acc: 0.9191\n",
            "Epoch 28/30\n",
            "6754/6754 [==============================] - 3s 448us/step - loss: 0.5436 - time_distributed_3_loss: 0.3636 - time_distributed_4_loss: 0.1800 - time_distributed_3_acc: 0.8961 - time_distributed_4_acc: 0.9252 - val_loss: 0.5593 - val_time_distributed_3_loss: 0.3728 - val_time_distributed_4_loss: 0.1866 - val_time_distributed_3_acc: 0.8923 - val_time_distributed_4_acc: 0.9202\n",
            "Epoch 29/30\n",
            "6754/6754 [==============================] - 3s 452us/step - loss: 0.5325 - time_distributed_3_loss: 0.3550 - time_distributed_4_loss: 0.1774 - time_distributed_3_acc: 0.8979 - time_distributed_4_acc: 0.9264 - val_loss: 0.5498 - val_time_distributed_3_loss: 0.3658 - val_time_distributed_4_loss: 0.1840 - val_time_distributed_3_acc: 0.8947 - val_time_distributed_4_acc: 0.9220\n",
            "Epoch 30/30\n",
            "6754/6754 [==============================] - 3s 451us/step - loss: 0.5217 - time_distributed_3_loss: 0.3465 - time_distributed_4_loss: 0.1752 - time_distributed_3_acc: 0.8991 - time_distributed_4_acc: 0.9273 - val_loss: 0.5437 - val_time_distributed_3_loss: 0.3602 - val_time_distributed_4_loss: 0.1835 - val_time_distributed_3_acc: 0.8950 - val_time_distributed_4_acc: 0.9210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc027024898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv-WKLdalVmW",
        "colab_type": "text"
      },
      "source": [
        "Протестируем и посмотрим на метрики."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7erY3-Iqttr",
        "colab_type": "code",
        "outputId": "f6445358-593d-4e07-a569-2049c865b33e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores = model.evaluate(x=test_sents, y=[to_categorical(test_pos),\n",
        "                                         to_categorical(test_anim)], )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2111/2111 [==============================] - 1s 588us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "traYEbL4sUgO",
        "colab_type": "code",
        "outputId": "6b9e6fe7-a39e-4cb8-9ab1-60994fa3d914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5706330581843034,\n",
              " 0.3736714443455709,\n",
              " 0.19696161021050093,\n",
              " 0.8916153452058699,\n",
              " 0.9164377099413942]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNlrNWV2UdaV",
        "colab_type": "code",
        "outputId": "c91c9a63-c970-48e4-9609-2ccc606684a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model.metrics_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss',\n",
              " 'time_distributed_3_loss',\n",
              " 'time_distributed_4_loss',\n",
              " 'time_distributed_3_acc',\n",
              " 'time_distributed_4_acc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Aae57OG9jW",
        "colab_type": "text"
      },
      "source": [
        "Тестируем на нашем предложении."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwLzu3ZCsNiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test_samples = [\n",
        "    \"эти типы стали есть на складе .\".split(),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpYyrQqZk4Gf",
        "colab_type": "text"
      },
      "source": [
        "Предобработаем предложения таким же способов как и обучающую выборку."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygWXMpfOnVzg",
        "colab_type": "code",
        "outputId": "2ab79e9d-573a-4b2b-cf55-15ff3bc51dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_samples_X = []\n",
        "for sent in test_samples:\n",
        "    sent_ids = []\n",
        "    for word in sent:\n",
        "        if word not in word2id:\n",
        "            print(word)\n",
        "        sent_ids.append(word2id.get(word.lower(), 1))\n",
        "    test_samples_X.append(sent_ids)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "есть\n",
            "складе\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9lJvCOQqFWA",
        "colab_type": "code",
        "outputId": "7294a534-cbaa-41f0-d90b-1e6634b1bf67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_samples_X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1695, 1766, 1022, 1, 2100, 1, 167]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBBdjilPnV1d",
        "colab_type": "code",
        "outputId": "ca0533ed-51a0-40de-b829-36cf5585b215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
        "print(test_samples_X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1458 1809 2052    1 1743    1 1406    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQPc6xdXnV4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(test_samples_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t64ePuFslGge",
        "colab_type": "text"
      },
      "source": [
        "Модель выдает по предикшену для каждого аутпута"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgujSXjrqLCz",
        "colab_type": "code",
        "outputId": "8f632844-5677-4084-a91e-a14ebcb18abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "len(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiubwR8xnV7h",
        "colab_type": "code",
        "outputId": "41290379-9b9d-4e15-a675-9d7551215eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "for i, idx in enumerate(predictions[0].argmax(axis=2)[0]):\n",
        "  if i > (len(test_samples[0])-1):\n",
        "    break\n",
        "  print(test_samples[0][i], id2pos[idx])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "эти ADJF\n",
            "типы NOUN\n",
            "стали VERB\n",
            "есть NOUN\n",
            "на PREP\n",
            "складе NOUN\n",
            ". PNCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWkwNnyzVcew",
        "colab_type": "code",
        "outputId": "0b776964-2757-42c2-8639-5918585b295e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "for i, idx in enumerate(predictions[1].argmax(axis=2)[0]):\n",
        "  if i > (len(test_samples[0])-1):\n",
        "    break\n",
        "  print(test_samples[0][i], id2anim[idx])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "эти NONE\n",
            "типы inan\n",
            "стали NONE\n",
            "есть NONE\n",
            "на NONE\n",
            "складе inan\n",
            ". NONE\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}