{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_HW1_Sidorova.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SerasLain/NLP-2019/blob/master/NLP_HW1_Sidorova.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VWmb8cEHhz-m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Домашняя работа 1: разделение текста на предложения\n",
        "## Анастасия Сидорова, БКЛ162"
      ]
    },
    {
      "metadata": {
        "id": "NqP8z6ysNvHB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drf98T9mh_sC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's get our sample!\n",
        "\n",
        "def get_file(path):\n",
        "  with open(path) as f:\n",
        "      bare_text = f.read()\n",
        "  return bare_text\n",
        "\n",
        "class Text():\n",
        "  def __init__(self):\n",
        "    self.bare_text = get_file('./Что делать.txt')\n",
        "    self.bare_sample = get_file('./sample_bare.txt')\n",
        "    self.ideal_sample = [i.strip() for i in get_file('./sample_ideal.txt').strip().split('\\n')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j1xVjr_zNrc_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Sentencer():\n",
        "  def simple_splitting(string):\n",
        "    regex = '[.?!]\\s[А-ЯЁ]'\n",
        "    sentences = re.split(regex, string.strip())\n",
        "    return sentences\n",
        "  \n",
        "  def evaluate(method, gold):\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    for sent in gold:\n",
        "      if len(method(sent)) == 1:\n",
        "          tp += 1\n",
        "      else:\n",
        "          fp += 1\n",
        "    for i in range(len(gold)-1):\n",
        "      sent1, sent2 = gold[i], gold[i+1]\n",
        "      sent = ' '.join([sent1, sent2])\n",
        "      if len(method(sent)) == 2:\n",
        "          tp += 1\n",
        "      else:\n",
        "          fn += 1\n",
        "    precision = (tp/(tp+fp))\n",
        "    recall = (tp/(tp+fn))\n",
        "    f1 = 2 * (precision * recall)/(precision + recall)\n",
        "    print('Precision - ', precision)\n",
        "    print('Recall - ', recall)\n",
        "    print('F1 - ', f1)\n",
        "    \n",
        "    def __init__(self):\n",
        "      self.sentences = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OuiVoKaiSDJ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = Text()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D7pUp4_lS43T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "da1ad19d-3a8d-42eb-dbb7-5a2c7f98959e"
      },
      "cell_type": "code",
      "source": [
        "# Metrics for simple splitting by '.?!'\n",
        "Sentencer.evaluate(Sentencer.simple_splitting, t.ideal_sample)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.8636363636363636\n",
            "Recall -  0.6627906976744186\n",
            "F1 -  0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i9TGMrGhUIzv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's train PunktSentenceTokenizer!\n",
        "\n",
        "from pprint import pprint\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n",
        "\n",
        "def train_pst():\n",
        "  trainer = PunktTrainer()\n",
        "  trainer.INCLUDE_ALL_COLLOCS = True\n",
        "  trainer.train(t.bare_text)\n",
        "  tokenizer = PunktSentenceTokenizer(trainer.get_params())\n",
        "  return tokenizer\n",
        "\n",
        "tokenize = train_pst().tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m9npjHcbXY-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d7c81bca-4a13-4098-8703-c7eb68eefd2f"
      },
      "cell_type": "code",
      "source": [
        "# Metrics for PunktSentenceTokenizer\n",
        "Sentencer.evaluate(tokenize, t.ideal_sample)\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.9259259259259259\n",
            "Recall -  0.8426966292134831\n",
            "F1 -  0.8823529411764706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oebpdn7oYnPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "bf321d2c-cabd-4e2f-b3a2-da076740735d"
      },
      "cell_type": "code",
      "source": [
        "# We've made some mistakes. Let's look through the list of sentences.\n",
        "\n",
        "tokenized = set(tokenize(t.bare_sample)) - set(t.ideal_sample)\n",
        "\n",
        "for i in tokenized:\n",
        "  print(i[-15:])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "о (т. XI, 1939.\n",
            " не возвращусь.\n",
            "даже в тревоге.\n",
            "овой идеологии.\n",
            "я подготовил С.\n",
            "ь лет спустя В.\n",
            "я осуществил С.\n",
            " \"Что делать?\"\"\n",
            "и \"Что делать?\"\n",
            " Б. Л. Кандель.\n",
            "ической борьбы.\n",
            "росил буфетчик.\n",
            "та исправлений.\n",
            " 3 часами ночи.\n",
            "ан Афанасьевич?\n",
            "А. Рейсер.\n",
            "о \"Что делать?\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KlLsb_rocG3P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adding abbreviaions\n",
        "tokenizer._params.abbrev_types.add('с')\n",
        "tokenizer._params.abbrev_types.add('в')\n",
        "tokenizer._params.abbrev_types.add('1939')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i27z0uk3dFej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "011b14e4-e54c-4d65-ac19-9f76535d3a3a"
      },
      "cell_type": "code",
      "source": [
        "# One more time\n",
        "tokenized = set(tokenizer.tokenize(t.bare_sample)) - (set(t.ideal_sample))\n",
        "for i in tokenized:\n",
        "  print(i)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Полицейский чиновник подошел к столу, - на столе лежал лист бумаги, а на нем крупными буквами было написано: \n",
            "\n",
            "\"Ухожу в 11 часов вечера и не возвращусь.\n",
            "и примечания подготовил С. А. Рейсер; статью \"Чернышевский-художник\" - Г. Е. Тамарченко; черновой текст - Т. И. Орнатская; библиографию переводов на иностранные языки - Б. Л. Кандель.\n",
            "Из рассказов о новых людях \n",
            "\n",
            "(Посвящается моему другу О.С.Ч.)  \n",
            "\n",
            "I \n",
            "\n",
            "ДУРАК \n",
            "\n",
            "Поутру 11 июля 1856 года прислуга одной из больших петербургских гостиниц у станции московской железной дороги была в недоумении, отчасти даже в тревоге.\n",
            "Основной текст романа, заметку для А. Н. Пыпина и Н. А. Некрасова, статью \"Проблемы изучения романа \"Что делать?\"\"\n",
            "Немало неточностей содержится и в издании \"Что делать?\"\n",
            "в составе 16-томного \"Полного собрания сочинений\" Чернышевского (т. XI, 1939. Гослитиздат, подготовка Н. А. Алексеева и А. П. Скафтымова): по сравнению с ним в этой книге более ста исправлений.\n",
            "был написан в стенах Петропавловской крепости в декабре 1862-апреле 1863 г. Вскоре же напечатанный в \"Современнике\", он сыграл колоссальную, ни с чем не сравнимую роль не только в художественной литературе, но и в истории русской общественно-политической борьбы.\n",
            "Меня услышат на Литейном мосту , между 2 и 3 часами ночи.\n",
            "- Что же такое, Иван Афанасьевич?\n",
            "- спросил буфетчик.\n",
            "Роман Н. Г. Чернышевского \"Что делать?\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "26eTepm4fFF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6cf6a81e-bd5e-43c6-9640-917b66b4ef67"
      },
      "cell_type": "code",
      "source": [
        "# Metrics for PunktSentenceTokenizer after correcting\n",
        "Sentencer.evaluate(tokenizer.tokenize, t.ideal_sample)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision -  0.9523809523809523\n",
            "Recall -  0.8791208791208791\n",
            "F1 -  0.9142857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_13Z8l-ajOg8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Вывод\n",
        "\n",
        "Кажется, что лучшего результата при помощи аббревиатур не добиться: часть ошибок произошла вследствие расхождения русской и английской пунктуации при оформлении заголовков и прямой речи. Как научить эту модель не реагировать на вопросительный знак перед кавычкой, мне непонятно."
      ]
    }
  ]
}